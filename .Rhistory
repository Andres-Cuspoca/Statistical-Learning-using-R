plot(summod2$adjr2,xlab="Number of Variables", ylab = "Adjusted R-squared,Larger the better")
which.max(summod2$adjr2)
points(11,summod2$cp[11],pch=20,col='blue')
plot(summod2$cp,xlab="Number of Variables", ylab = "Cp statistic-Lesser The better")
points(10,summod2$cp[10],pch=20,col='blue')#coloring the Best Model with 10 predictors
plot(summod2$adjr2,xlab="Number of Variables", ylab = "Adjusted R-squared,Larger the better")
which.max(summod2$adjr2)
points(11,summod2$cp[11],pch=20,col='blue')
plot(summod2$cp,xlab="Number of Variables", ylab = "Cp statistic-Lesser The better")
points(10,summod2$cp[10],pch=20,col='blue')#coloring the Best Model with 10 predictors
plot(summod2$adjr2,xlab="Number of Variables", ylab = "Adjusted R-squared,Larger the better")
which.max(summod2$adjr2)
points(11,summod2$cp[11],pch=20,col='blue')
which.min(summod2$adjr2)
which.min(summod2$cp)
coef(summod2$cp[10])
coef(Mod2[10])
coef(Mod2$cp[10])
coef(Mod2,id = 10)
coef(Mod2,10)
forwmod<-regsubsets(Salary ~ . , data  = Hitters , method = 'forward',nvmax = 19 )
sumfor<-summary(forwmod)
sumfor
sumfor$rsq
sumfor$cp
sumfor$bic
sumfor$adjr2
which.max(sumfor$adjr2)
sumfor$outmat
plot(sumfor$adjr2,xlab="Number of Variables" , ylab =  " Adjusted R-squared")
plot(sumfor$adjr2,xlab="Number of Variables" , ylab =  " Adjusted R-squared")
plot(sumfor$bic,xlab='Number of Predictors '  , ylab = "BIS statistic")
title("Forward Stepwise Selection")
plot(sumfor$adjr2,xlab="Number of Variables" , ylab =  " Adjusted R-squared")
plot(sumfor$bic,xlab='Number of Predictors '  , ylab = "BIS statistic")
title("Forward Stepwise Selection")
title("Forward Stepwise Selection")
plot(sumfor$adjr2,xlab="Number of Variables" , ylab =  " Adjusted R-squared")
plot(sumfor$bic,xlab='Number of Predictors '  , ylab = "BIS statistic")
plot(sumfor$adjr2,xlab="Number of Variables" , ylab =  " Adjusted R-squared")
title("Forward Stepwise Selection")
plot(sumfor$bic,xlab='Number of Predictors '  , ylab = "BIS statistic")
plot(sumfor$adjr2,xlab="Number of Variables" , ylab =  " Adjusted R-squared")
title("Forward Stepwise Selection")
plot(sumfor$bic,xlab='Number of Predictors '  , ylab = "BIC statistic")
which.min(sumfor$bic)
which.max(sumfor$adjr2)
points(6,sumfor$bic[6],pch=20,col='red')
plot(sumfor$adjr2,xlab="Number of Variables" , ylab =  " Adjusted R-squared")
title("Forward Stepwise Selection")
plot(sumfor$bic,xlab='Number of Predictors '  , ylab = "BIC statistic")
points(6,sumfor$bic[6],pch=20,col='red')
points(11,sumfor$adjr2[11],pch=20,col='blue')
plot(sumfor$adjr2,xlab="Number of Variables" , ylab =  " Adjusted R-squared")
points(11,sumfor$adjr2[11],pch=20,col='blue')
title("Forward Stepwise Selection")
plot(sumfor$bic,xlab='Number of Predictors '  , ylab = "BIC statistic")
points(6,sumfor$bic[6],pch=20,col='red')
which.max(sumfor$adjr2)
sumfor$adjr2
max(sumfor$adjr2)
sumfor$adjr2
sumfor$bic
class(sumfor)
as.data.frame(sumfor)
backmod<-regsubsets(Salary ~ . , data  = Hitters , method = 'backward ', nvmax = 19 )
backmod<-regsubsets(Salary ~ . , data  = Hitters , method = 'back', nvmax = 19 )
backsum<-summary(backmod)
backsum
backsum$rss
which.min(backsum$rss)
backsum$adjr2
which.max(backsum$adjr2)
which.min(backsum$cp)
which.min(backsum$bic)
which.max(backsum$adjr2)
which.min(backsum$bic)
plot(sumfor$adjr2,xlab="Number of Variables" , ylab =  " Adjusted R-squared")
points(11,sumfor$adjr2[11],pch=20,col='blue')
#Adjst R-squred is highest for Model with 11 predictors
title("Backward Stepwise Selection")
plot(sumfor$bic,xlab='Number of Predictors '  , ylab = "BIC statistic")
points(8,sumfor$bic[8],pch=20,col='red')
#BIC is least for a model with 8 predictors
coef(backmod,id=8)
predict(backmod[8],newdata  )
plot(sumfor$adjr2,xlab="Number of Variables" , ylab =  " Adjusted R-squared")
points(11,sumfor$adjr2[11],pch=20,col='green')
#Adjst R-squred is highest for Model with 11 predictors
title("Backward Stepwise Selection")
plot(sumfor$bic,xlab='Number of Predictors '  , ylab = "BIC statistic")
points(8,sumfor$bic[8],pch=20,col='yellow')
#BIC is least for a model with 8 predictors
plot(backsum$rss,xlab="Number of Variables",ylab = "Residual Sum of Squared Error on Training Data")
plot(backsum$rss/nrow(Hitters),xlab="Number of Variables",ylab = "Residual Sum of Squared Error on Training Data")
par(mfrow=c(1,1))
plot(backsum$rss/nrow(Hitters),xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,pch=19,col='blue',type='b')
plot(backsum$rss/nrow(Hitters),xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,pch=19,col='blue',type='b')
plot(backsum$rss/nrow(Hitters),xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,pch=19,col='blue',type='b')
plot(backsum$rss/nrow(Hitters),xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,col='blue',type='b')
par(mfrow=c(1,1))
plot(backsum$rss/nrow(Hitters),xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
lines(backsum$bic,col='blue',type='b')
plot(backsum$rss/nrow(Hitters),xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,col='blue',pch=19,type='b')
plot(backsum$rss/nrow(Hitters),xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,col='blue',pch=19,type='b')
plot(backsum$rss/nrow(Hitters),xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$rss,col='blue',pch=19,type='b')
plot(backsum$rss/nrow(Hitters),type='b',xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$rss,col='blue',pch=19,type='b')
points(backsum$rss,col='blue',pch=19,type='b')
par(mfrow=c(1,1))
plot(backsum$rss/nrow(Hitters),type='b',xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,col='red',pch=19,type='b')
?points
points(backsum$bic,col='red',pch=19,type='b')
par(mfrow=c(1,1))
plot(backsum$rss/nrow(Hitters),type='b',xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,col='red',pch=19,type='b')
points(backsum$bic,y = NULL,col='red',pch=19,type='b')
points(backsum$bic,y = NULL,col='red',pch=19,type='l')
points(backsum$bic,y = NULL,col='red',pch=19,type='h')
points(backsum$bic,y = NULL,col='red',pch=19,type='b')
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,y = NULL,col='red',pch=19,type='b')
points(backsum$bic,y = NULL,col='red',pch=19,type='b')
points(backsum$bic,y = NULL,col='red',pch=20,type='b')
plot(backsum$rss/nrow(Hitters),type='b',pch=21,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,y = NULL,col='red',pch=20,type='b')
plot(backsum$rss/nrow(Hitters),type='b',pch=22,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,y = NULL,col='red',pch=20,type='b')
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
length(backsum$bic)
plot(x = degree , y = cv.error,type='b' ,title="Cross validation error for different degrees",xlab = "Degree",ylab = "Cross validation error")
plot(degree, cv.error10,type='b',col='red',xlab="Degree of polynomial",ylab ="10 fold CV error vs 5 fold")
#Hence we can see that Model with quadratic degree is the best one with least
lines(degree, cv.error5 , col = 'blue',type= 'b')
legend("topright", c("5-fold CV","10-fold CV"),col=c("blue","red"),pch=19)
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,pch=19,col="blue",type='b')
plot(backsum$rss/nrow(Hitters),y=NULL,type='b',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,pch=19,col="blue",type='b')
plot(backsum$rss/nrow(Hitters),y=NULL,type='b',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,y=NULL,pch=19,col="blue",type='b')
lines(backsum$bic,y=NULL,pch=19,col="blue",type='b')
plot(backsum$rss/nrow(Hitters),y=NULL,type='b',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,y=NULL,pch=19,col="blue",type='b')
plot(backsum$rss/nrow(Hitters),y=NULL,type='p',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,y=NULL,pch=19,col="blue",type='p')
plot(backsum$rss/nrow(Hitters),y=NULL,type='b',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,y=NULL,pch=19,col="blue",type='b')
plot(backsum$rss/nrow(Hitters),y=NULL,type='b',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$adjr2,y=NULL,pch=19,col="blue",type='b')
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
points(backsum$bic,pch=19,col="blue",type='b')
par(mfrow=c(2,1))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
plot(backsum$bic,type='b',pch=19,xlab="Number of variables",
ylab="BIC value")
par(mfrow=c(1,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",ylab = "Mean Squared Error on Training Data")
plot(backsum$bic,type='b',pch=19,xlab="Number of variables",
ylab="BIC value")
par(mfrow=c(2,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",xlab="Number of variables",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',xlab="Number of variables",
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,xlab="Number of variables",
ylab('Adjusted R-squared'))
par(mfrow=c(2,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",xlab="Number of variables",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',xlab="Number of variables",
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,xlab="Number of variables",
ylab=('Adjusted R-squared'))
par(mfrow=c(2,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",xlab="Number of variables",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',xlab="Number of variables",
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,xlab="Number of variables",
ylab=('Adjusted R-squared'))
par(mfrow=c(2,1))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",xlab="Number of variables",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',xlab="Number of variables",
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,xlab="Number of variables",
ylab=('Adjusted R-squared'))
par(mfrow=c(2,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",xlab="Number of variables",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',xlab="Number of variables",
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,xlab="Number of variables",
ylab=('Adjusted R-squared'))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",xlab="Number of variables",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',xlab="Number of variables",
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,xlab="Number of variables",
ylab=('Adjusted R-squared'))
par(mfrow=c(4,1))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",xlab="Number of variables",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',xlab="Number of variables",
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,xlab="Number of variables",
ylab=('Adjusted R-squared'))
par(mfrow=c(2,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",xlab="Number of variables",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',xlab="Number of variables",
ylab="R-squared in Training data")
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,
ylab=('Adjusted R-squared'))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,
ylab=('Adjusted R-squared'))
par(mfrow=c(2,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,
ylab=('Adjusted R-squared'))
par(mfrow=c(2,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,
ylab=('Adjusted R-squared'))
par(mfrow=c(2,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,
ylab=('Adjusted R-squared'))
par(mar=rep(2,2))
par(mar=rep(2,4))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,
ylab=('Adjusted R-squared'))
par(mar=rep(2,6))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,
ylab=('Adjusted R-squared'))
par(mar=rep(2,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,
ylab=('Adjusted R-squared'))
par(mar=c(2,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,
ylab=('Adjusted R-squared'))
par(mfrow=c(2,2))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,
ylab=('Adjusted R-squared'))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting")
plot(backsum$bic,type='b',pch=19,col="blue",xlab="Number of Variables",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',xlab="Number of Variables",
ylab="R-squared in Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,xlab="Number of Variables",
ylab=('Adjusted R-squared'))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Standard Cases of Overfitting as increase in Model Variance as no of Predictors Increase")
plot(backsum$bic,type='b',pch=19,col="blue",xlab="Number of Variables",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',xlab="Number of Variables",
ylab="R-squared on Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,xlab="Number of Variables",
ylab=('Adjusted R-squared'))
plot(backsum$rss/nrow(Hitters),type='b',pch=19,xlab="Number of Variables",
ylab = "Mean Squared Error on Training Data")
title("Overfitting Cases and increase in Model Variance as no of Predictors Increases")
plot(backsum$bic,type='b',pch=19,col="blue",xlab="Number of Variables",
ylab="BIC value")
plot(backsum$rsq,type="b",pch=19,col='red',xlab="Number of Variables",
ylab="R-squared on Training data")
plot(backsum$adjr2,type='b',col='green',pch=19,xlab="Number of Variables",
ylab=('Adjusted R-squared'))
require(glmnet)
cv.glmnet
install.packages("glmnet")
require(glmnet)
?cv.glmnet
dim(Hitters)
263*2/2
263*2/3
263*1/3
trainrow<-sample(seq(263),180,replace = FALSE)
head(trainrow)
forw<-regsubsets(Salary ~ . ,data=Hitters[trainrow,] ,
method = "forward",nvmax =19)
require(leaps)
forw<-regsubsets(Salary ~ . ,data=Hitters[trainrow,] ,
method = "forward",nvmax =19)
val.error<-rep(NA,19)
?model.matrix()
x.test<-model.matrix(Salary ~ ., data = Hitters[-trainrow,])
View(Xy)
View(x.test)
dim(x.test)
for(i in 1:19) {
coefi = coef(forw , id = i)
pred = x.test[,names(coefi)]%*%coefi
val.error = mean((Hitters$Salary[-trainrow]-pred )^2)#Mean sqrd Error on Test set
}
coefi
for(i in 1:19) {
coefi = coef(forw , id = i)
pred = x.test[,names(coefi)]%*%coefi
val.error[i] = mean((Hitters$Salary[-trainrow]-pred )^2)#Mean sqrd Error on Test set
}
which.min(val.error)
val.error
plot(sqrt(val.error),pch=19,type='b',ylab="RMS error on Test Set",xlab="No of Predictors")
points(sqrt(forw$rss[-1]/180),type='b',pch=19,col='blue')
points(sqrt(forw$rss/180),type='b',pch=19,col='blue')
plot(sqrt(val.error),pch=19,type='b',ylab="RMS error on Test Set",xlab="No of Predictors")
points(sqrt(forw$rss[-1]/180),type='b',pch=19,col='blue')
summary(forw)
legend('topright',c("MSE on Test Set ","MSE on Training Data"),col=c("black","blue"))
plot(sqrt(val.error),pch=19,ylim=c(280,400),type='b',ylab="RMS error on Test Set",xlab="No of Predictors")
#also adding the Mean RSS omn training data
points(sqrt(forw$rss[-1]/180),type='b',pch=19,col='blue')
legend('topright',c("MSE on Test Set ","MSE on Training Data"),col=c("black","blue"))
legend('topright',pch=19,c("MSE on Test Set ","MSE on Training Data"),col=c("black","blue"))
plot(sqrt(val.error),pch=19,ylim=c(280,400),type='b',ylab="RMS error on Test Set",xlab="No of Predictors")
#also adding the Mean RSS omn training data
title("MSE on TEST SET vs MSE on TRAIN SET")
points(sqrt(forw$rss[-1]/180),type='b',pch=19,col='blue')
legend('topright',pch=19,c("MSE on Test Set ","MSE on Training Data"),col=c("black","blue"))
#AS expected the MSE in Training data decrease as the no of predictors
#in the Model Increases due to forward stepwise which adds 1 mor
plot(sqrt(val.error),pch=19,ylim=c(280,400),type='b',ylab="RMS error",xlab="No of Predictors")
#also adding the Mean RSS omn training data
title("MSE on TEST SET vs MSE on TRAIN SET")
points(sqrt(forw$rss[-1]/180),type='b',pch=19,col='blue')
legend('topright',pch=19,c("MSE on Test Set ","MSE on Training Data"),col=c("black","blue"))
head(pred)
predict.regsubset<-function(object,newdata,id,...)
{
form=as.formula(object$call[[2]])
mat<-model.matrix(form,newdata)#Test Set
coefi<-coef(object,id=id)# Model coefficients
#last line are the predicted values
mat[,names(coefi)]%*%coefi
}
set.seed(10)
?rep
rep(1)
rep(1,20)
rep(1:10,20)
rep(1:10,19)
folds=sample(rep(1:10,length = nrow(Hitters)))
folds
table(folds)
folds
cv.errors<-rep(NA,19)
cv.errors<-matrix(NA,10,19)
for(k in 1:10)
{
#fitting the Models on each k-1 folds
best.fit<-regsubsets(Salary ~ . , data = Hitters[folds!=k,],
nvmax=19,method='forward')
}
for(i in 1:19)
{
pred = predict.regsubset(best.fit,Hitters[folds==k,],
id=i)
cv.errors[k,i]=mean((Hitters$Salary[folds==k]-pred)^2)
}
for(k in 1:10)
{
#fitting the Models on each k-1 folds
best.fit<-regsubsets(Salary ~ . , data = Hitters[folds!=k,],
nvmax=19,method='forward')
#predictions on left out Kth fold -Validation Set
for(i in 1:19)
{
pred = predict.regsubset(best.fit,Hitters[folds==k,],
id=i)
cv.errors[k,i]=mean((Hitters$Salary[folds==k]-pred)^2)
}
}
head(cv.errors)
pred
pred
rmse.cv=sqrt(apply(cv.errors,2,mean))
rmse.cv
plot(rmse.cv,pch=19,type='b')
plot(rmse.cv,pch=19,type='b',ylab="Root Mean squared Cross validation Error",
xlab="Number of Predictors",title="CV error for each Submodel")
plot(rmse.cv,pch=19,type='b',ylab="Root Mean squared Cross validation Error",
xlab="Number of Predictors")
title("CV error for each Submodel")
best.fit
points(sqrt(best.fit$rss[-1]/180),pch=19,col='blue',type='b')
plot(rmse.cv,pch=19,type='b',ylim=c(320,400),ylab="Root Mean squared Cross validation Error",
xlab="Number of Predictors")
points(sqrt(best.fit$rss[-1]/180),pch=19,col='blue',type='b')
title("CV error for each Submodel")
plot(rmse.cv,pch=19,type='b',ylim=c(320,420),ylab="Root Mean squared Cross validation Error",
xlab="Number of Predictors")
points(sqrt(best.fit$rss[-1]/180),pch=19,col='blue',type='b')
title("CV error for each Submodel")
plot(rmse.cv,pch=19,type='b',ylim=c(320,460),ylab="Root Mean squared Cross validation Error",
xlab="Number of Predictors")
points(sqrt(best.fit$rss[-1]/180),pch=19,col='blue',type='b')
title("CV error for each Submodel")
plot(rmse.cv,pch=19,type='b',ylim=c(320,440),ylab="Root Mean squared Cross validation Error",
xlab="Number of Predictors")
points(sqrt(best.fit$rss[-1]/180),pch=19,col='blue',type='b')
title("CV error for each Submodel")
which.min(best.fit$rss)
plot(rmse.cv,pch=19,type='b',ylim=c(320,440),ylab="Root Mean squared Cross validation Error",
xlab="Number of Predictors")
title("CV error for each Submodel")
plot(rmse.cv,pch=19,type='b',ylim=c(320,400),ylab="Root Mean squared Cross validation Error",
xlab="Number of Predictors")
title("CV error for each Submodel")
