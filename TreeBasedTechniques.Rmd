---
title: "Tree Based Methods in R"
output: html_notebook
---




### This is a article on how to implement Tree based Techniques in R to do Predictive Modelling
 
It will include implementation of Decision Trees ,  Random Forests and other Tree based variants.



-----------



#### Loading the required Packages

```{r,warning=FALSE,message=FALSE}
require(ISLR) #package containing data
require(ggplot2)
require(tree)

#Using the Carseats data set 

attach(Carseats)
?Carseats


```


Carseats is a simulated data set containing sales of child car seats at 400 different stores.


```{r}
#Checking the distribution of Sales

ggplot(aes(x = Sales),data = Carseats) + 
  geom_histogram(color="black",fill = 'purple',alpha = 0.6, bins=30) + 
  labs(x = "Unit Sales in Thousands", y = "Frequency")


```
As the histogram suggests - It is Normally distributed
Highest frequency of around 8000 Unit Sales


```{r}

#Making a Factor variable from Sales

HighSales<-ifelse(Sales <= 8,"No","Yes")
head(HighSales)

#Making a Data frame
Carseats<-data.frame(Carseats,HighSales)


```


----------




## Fitting a Binary Classification Tree



Now we are going to fit a __Tree__ to the Carseats Data to predict if we are going to have High Sales or not.

```{r}
#We will use the tree() function to fit a Desicion Tree
?tree

#Excluding the Sales atrribute
CarTree<-tree(HighSales ~ . -Sales , data = Carseats,split = c("deviance","gini"))
#split argument split	to specify the splitting criterion to use.

CarTree #Outputs a Tree with various Splits at different Variables and Response at Terminals Nodes

#Summary of the Decision Tree
summary(CarTree)


```



